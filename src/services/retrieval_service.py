# src/services/retrieval_service.py
"""
ç»Ÿä¸€çš„å¬å›æœåŠ¡
documents.pyï¼ˆæµ‹è¯•ï¼‰å’Œ chat.pyï¼ˆå®é™…ä½¿ç”¨ï¼‰éƒ½è°ƒç”¨è¿™ä¸ª
"""

from typing import List, Tuple, Optional, Dict, Any
from langchain_core.documents import Document
from langchain_chroma import Chroma
from sentence_transformers import CrossEncoder
from langchain_huggingface import HuggingFaceEmbeddings
from pathlib import Path

CHROMA_PERMANENT_DIR = Path("data/vectorstore/permanent")  # æ­£å¼åº“

# å…¨å±€ rerankerï¼ˆä¸ documents.py ä¸€è‡´ï¼‰
try:
    from models.model_paths import get_models_cache_dir

    reranker_model = CrossEncoder(
        model_name_or_path=get_models_cache_dir() + '/BAAI-bge-reranker-large',
        max_length=512,
        device='cpu'
    )
    print("âœ… Rerankeræ¨¡å‹åŠ è½½æˆåŠŸ")
except Exception as e:
    print(f"âš ï¸ Rerankeræ¨¡å‹åŠ è½½å¤±è´¥: {e}")
    reranker_model = None

# åˆå§‹åŒ–embeddingæ¨¡å‹ï¼ˆå…¨å±€å…±äº«ï¼‰
print("ğŸ“¦ åˆå§‹åŒ– Embedding æ¨¡å‹...")
embedding_model = HuggingFaceEmbeddings(
    model_name="BAAI/bge-large-zh-v1.5",
    cache_folder=get_models_cache_dir(),
    model_kwargs={
        "device": "cpu",
        "local_files_only": True
    }
)
print("âœ… Embedding æ¨¡å‹åŠ è½½æˆåŠŸ")

def retrieve_with_rerank(
        vectorstore: Chroma,
        query: str,
        top_k: int = 5,
        use_rerank: bool = False,
        threshold: Optional[float] = None
) -> List[Tuple[Document, float]]:
    """
    ç»Ÿä¸€çš„å¬å›å‡½æ•°

    :param vectorstore: Chroma å‘é‡åº“å®ä¾‹
    :param query: æŸ¥è¯¢æ–‡æœ¬
    :param top_k: è¿”å› top-k ç»“æœ
    :param use_rerank: æ˜¯å¦å¯ç”¨ rerank äºŒæ¬¡ç²¾æ’
    :param threshold: ç›¸ä¼¼åº¦é˜ˆå€¼ï¼ˆå¯é€‰ï¼‰
    :return: [(Document, score), ...] åˆ—è¡¨
    """

    # 1. å¬å›ï¼ˆå¦‚æœå¯ç”¨ rerankï¼Œå¤šå¬å›ä¸€äº›ç”¨äºç²¾æ’ï¼‰
    initial_k = top_k * 3 if use_rerank else top_k

    results_with_scores = vectorstore.similarity_search_with_score(
        query,
        k=initial_k
    )

    # 2. è½¬æ¢ä¸ºç»Ÿä¸€æ ¼å¼ï¼ˆdistance â†’ similarityï¼‰
    results = []
    for doc, distance in results_with_scores:
        similarity = 1 - distance  # Chroma è¿”å›çš„æ˜¯ distance

        # é˜ˆå€¼è¿‡æ»¤
        if threshold is not None and similarity < threshold:
            continue

        results.append((doc, similarity))

    # 3. Rerank äºŒæ¬¡ç²¾æ’ï¼ˆå¦‚æœå¯ç”¨ï¼‰
    if use_rerank and len(results) > 0:
        results = _rerank_results(query, results, top_k)

    # 4. è¿”å› top_k ä¸ªç»“æœ
    return results[:top_k]


def _rerank_results(
        query: str,
        results: List[Tuple[Document, float]],
        top_k: int
) -> List[Tuple[Document, float]]:
    """ä½¿ç”¨ BGE reranker è¿›è¡ŒäºŒæ¬¡ç²¾æ’"""

    if reranker_model is None:
        print("âš ï¸ Reranker ä¸å¯ç”¨ï¼Œè¿”å›åŸå§‹ç»“æœ")
        return results[:top_k]

    try:
        # å‡†å¤‡ query-document å¯¹
        pairs = [[query, doc.page_content] for doc, _ in results]

        # è®¡ç®— rerank åˆ†æ•°
        rerank_scores = reranker_model.predict(pairs)

        # æ›´æ–°åˆ†æ•°å¹¶é‡æ–°æ’åº
        reranked = []
        for i, (doc, _) in enumerate(results):
            reranked.append((doc, float(rerank_scores[i])))

        # æŒ‰ rerank åˆ†æ•°é™åºæ’åº
        reranked.sort(key=lambda x: x[1], reverse=True)

        return reranked[:top_k]

    except Exception as e:
        print(f"âš ï¸ Rerank å¤±è´¥: {e}")
        return results[:top_k]