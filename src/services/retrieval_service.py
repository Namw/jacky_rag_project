# src/services/retrieval_service.py
"""
ç»Ÿä¸€çš„å¬å›æœåŠ¡
documents.pyï¼ˆæµ‹è¯•ï¼‰å’Œ chat.pyï¼ˆå®é™…ä½¿ç”¨ï¼‰éƒ½è°ƒç”¨è¿™ä¸ª
"""

from typing import List, Tuple, Optional
from langchain_core.documents import Document
from langchain_chroma import Chroma
from pathlib import Path

from models.model_factory_ebd import ModelFactoryEbd

CHROMA_PERMANENT_DIR = Path("data/vectorstore/permanent")  # æ­£å¼åº“

# ==================== å…¨å±€æ¨¡å‹å®ä¾‹ï¼ˆæ‡’åŠ è½½ï¼‰====================
print(f"ğŸ”§ å½“å‰æ¨¡å‹æä¾›å•†: {ModelFactoryEbd.get_provider()}")

def get_embedding_model():
    """è·å– Embedding æ¨¡å‹"""
    return ModelFactoryEbd.get_embedding_model()


def get_reranker_model():
    """è·å– Reranker æ¨¡å‹"""
    return ModelFactoryEbd.get_reranker_model()


def retrieve_with_rerank(
        vectorstore: Chroma,
        query: str,
        top_k: int = 5,
        use_rerank: bool = False,
        threshold: Optional[float] = None
) -> List[Tuple[Document, float]]:
    """
    ç»Ÿä¸€çš„å¬å›å‡½æ•°

    :param vectorstore: Chroma å‘é‡åº“å®ä¾‹
    :param query: æŸ¥è¯¢æ–‡æœ¬
    :param top_k: è¿”å› top-k ç»“æœ
    :param use_rerank: æ˜¯å¦å¯ç”¨ rerank äºŒæ¬¡ç²¾æ’
    :param threshold: ç›¸ä¼¼åº¦é˜ˆå€¼ï¼ˆå¯é€‰ï¼‰
    :return: [(Document, score), ...] åˆ—è¡¨
    """

    # 1. å¬å›ï¼ˆå¦‚æœå¯ç”¨ rerankï¼Œå¤šå¬å›ä¸€äº›ç”¨äºç²¾æ’ï¼‰
    initial_k = top_k * 3 if use_rerank else top_k

    results_with_scores = vectorstore.similarity_search_with_score(
        query,
        k=initial_k
    )

    # 2. è½¬æ¢ä¸ºç»Ÿä¸€æ ¼å¼ï¼ˆdistance â†’ similarityï¼‰
    results = []
    for doc, distance in results_with_scores:
        similarity = 1 - distance  # Chroma è¿”å›çš„æ˜¯ distance

        # é˜ˆå€¼è¿‡æ»¤
        if threshold is not None and similarity < threshold:
            continue

        results.append((doc, similarity))

    # 3. Rerank äºŒæ¬¡ç²¾æ’ï¼ˆå¦‚æœå¯ç”¨ï¼‰
    if use_rerank and len(results) > 0:
        results = _rerank_results(query, results, top_k)

    # 4. è¿”å› top_k ä¸ªç»“æœ
    return results[:top_k]


def _rerank_results(
        query: str,
        results: List[Tuple[Document, float]],
        top_k: int
) -> List[Tuple[Document, float]]:
    """ä½¿ç”¨ Reranker è¿›è¡ŒäºŒæ¬¡ç²¾æ’ï¼ˆå…¼å®¹æœ¬åœ°å’Œé˜¿é‡Œäº‘æ¨¡å‹ï¼‰"""

    reranker_model = get_reranker_model()

    if reranker_model is None:
        print("âš ï¸ Reranker ä¸å¯ç”¨ï¼Œè¿”å›åŸå§‹ç»“æœ")
        return results[:top_k]

    try:
        # å‡†å¤‡ query-document å¯¹
        pairs = [[query, doc.page_content] for doc, _ in results]

        # è®¡ç®— rerank åˆ†æ•°ï¼ˆç»Ÿä¸€æ¥å£ï¼‰
        rerank_scores = reranker_model.predict(pairs)

        # æ›´æ–°åˆ†æ•°å¹¶é‡æ–°æ’åº
        reranked = []
        for i, (doc, _) in enumerate(results):
            reranked.append((doc, float(rerank_scores[i])))

        # æŒ‰ rerank åˆ†æ•°é™åºæ’åº
        reranked.sort(key=lambda x: x[1], reverse=True)

        return reranked[:top_k]

    except Exception as e:
        print(f"âš ï¸ Rerank å¤±è´¥: {e}")
        return results[:top_k]

embedding_model = get_embedding_model()
