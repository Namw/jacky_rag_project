# src/services/model_factory.py
"""
æ¨¡å‹å·¥å‚ - ç»Ÿä¸€ç®¡ç† Embedding å’Œ Reranker æ¨¡å‹çš„åŠ è½½
"""

import os
import dashscope
from dashscope import TextReRank
from langchain_huggingface import HuggingFaceEmbeddings
from sentence_transformers import CrossEncoder
from models.model_paths import get_models_cache_dir
from langchain_community.embeddings import DashScopeEmbeddings

class ModelFactoryEbd:
    """æ¨¡å‹å·¥å‚ç±»ï¼Œæ ¹æ®é…ç½®åŠ è½½å¯¹åº”çš„æ¨¡å‹"""

    _embedding_model = None
    _reranker_model = None

    @staticmethod
    def get_provider() -> str:
        """è·å–å½“å‰æ¨¡å‹æä¾›å•†"""
        return os.getenv("MODEL_PROVIDER", "aliyun").lower()

    @staticmethod
    def get_embedding_model():
        """è·å– Embedding æ¨¡å‹ï¼ˆå•ä¾‹æ¨¡å¼ï¼‰"""
        if ModelFactoryEbd._embedding_model is None:
            provider = ModelFactoryEbd.get_provider()

            if provider == "local":
                ModelFactoryEbd._embedding_model = ModelFactoryEbd._load_local_embedding()
            elif provider == "aliyun":
                ModelFactoryEbd._embedding_model = ModelFactoryEbd._load_aliyun_embedding()
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„æ¨¡å‹æä¾›å•†: {provider}")

        return ModelFactoryEbd._embedding_model

    @staticmethod
    def get_reranker_model():
        """è·å– Reranker æ¨¡å‹ï¼ˆå•ä¾‹æ¨¡å¼ï¼‰"""
        if ModelFactoryEbd._reranker_model is None:
            provider = ModelFactoryEbd.get_provider()
            if provider == "local":
                ModelFactoryEbd._reranker_model = ModelFactoryEbd._load_local_reranker()
            elif provider == "aliyun":
                ModelFactoryEbd._reranker_model = ModelFactoryEbd._load_aliyun_reranker()
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„æ¨¡å‹æä¾›å•†: {provider}")

        return ModelFactoryEbd._reranker_model

    # ==================== æœ¬åœ°æ¨¡å‹åŠ è½½ ====================

    @staticmethod
    def _load_local_embedding():
        """åŠ è½½æœ¬åœ° Embedding æ¨¡å‹"""
        try:
            model_name = "BAAI/bge-large-zh-v1.5"
            print(f"ğŸ“¦ åŠ è½½æœ¬åœ° Embedding æ¨¡å‹: {model_name}")
            embedding_model = HuggingFaceEmbeddings(
                model_name=model_name,
                cache_folder=get_models_cache_dir(),
                model_kwargs={
                    "device": "cpu",
                    "local_files_only": True
                }
            )
            print("âœ… æœ¬åœ° Embedding æ¨¡å‹åŠ è½½æˆåŠŸ")
            return embedding_model

        except Exception as e:
            print(f"âŒ æœ¬åœ° Embedding æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            raise

    @staticmethod
    def _load_local_reranker():
        """åŠ è½½æœ¬åœ° Reranker æ¨¡å‹"""
        try:
            model_name = "/BAAI-bge-reranker-large"
            model_path = get_models_cache_dir() + f'/{model_name}'

            print(f"ğŸ“¦ åŠ è½½æœ¬åœ° Reranker æ¨¡å‹: {model_name}")
            reranker_model = CrossEncoder(
                model_name_or_path=model_path,
                max_length=512,
                device='cpu'
            )
            print("âœ… æœ¬åœ° Reranker æ¨¡å‹åŠ è½½æˆåŠŸ")
            return reranker_model

        except Exception as e:
            print(f"âš ï¸ æœ¬åœ° Reranker æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            return None

    # ==================== é˜¿é‡Œäº‘æ¨¡å‹åŠ è½½ ====================

    @staticmethod
    def _load_aliyun_embedding():
        """åŠ è½½é˜¿é‡Œäº‘ Embedding æ¨¡å‹"""
        try:
            api_key = os.getenv("DASHSCOPE_API_KEY")
            if not api_key:
                raise ValueError("è¯·åœ¨ .env ä¸­é…ç½® DASHSCOPE_API_KEY")
            model_name = "text-embedding-v4"
            print(f"ğŸ“¦ åŠ è½½é˜¿é‡Œäº‘ Embedding æ¨¡å‹: {model_name}")
            embedding_model = DashScopeEmbeddings(
                model=model_name,
                dashscope_api_key=api_key
            )
            print("âœ… é˜¿é‡Œäº‘ Embedding æ¨¡å‹åŠ è½½æˆåŠŸ")
            return embedding_model

        except Exception as e:
            print(f"âŒ é˜¿é‡Œäº‘ Embedding æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            raise

    @staticmethod
    def _load_aliyun_reranker():
        """åŠ è½½é˜¿é‡Œäº‘ Reranker æ¨¡å‹ï¼ˆè¿”å›åŒ…è£…å™¨ï¼‰"""
        try:
            api_key = os.getenv("DASHSCOPE_API_KEY")
            if not api_key:
                raise ValueError("è¯·åœ¨ .env ä¸­é…ç½® DASHSCOPE_API_KEY")
            dashscope.api_key = api_key
            model_name = "qwen3-rerank"
            print(f"ğŸ“¦ åŠ è½½é˜¿é‡Œäº‘ Reranker æ¨¡å‹: {model_name}")
            print("âœ… é˜¿é‡Œäº‘ Reranker æ¨¡å‹é…ç½®æˆåŠŸ")
            # è¿”å›ä¸€ä¸ªåŒ…è£…å™¨ï¼Œä½¿å…¶æ¥å£ä¸æœ¬åœ°æ¨¡å‹ä¸€è‡´
            return AliyunRerankerWrapper(model_name, api_key)
        except Exception as e:
            print(f"âš ï¸ é˜¿é‡Œäº‘ Reranker æ¨¡å‹é…ç½®å¤±è´¥: {e}")
            return None


class AliyunRerankerWrapper:
    """é˜¿é‡Œäº‘ Reranker çš„åŒ…è£…å™¨ï¼Œç»Ÿä¸€æ¥å£"""

    def __init__(self, model_name: str, api_key: str):
        self.model_name = model_name
        self.api_key = api_key
        dashscope.api_key = api_key

    def predict(self, pairs):
        """
        ä¸ CrossEncoder æ¥å£ä¿æŒä¸€è‡´
        pairs: [[query, doc], [query, doc], ...]
        è¿”å›: [score1, score2, ...]
        """
        if not pairs:
            return []

        query = pairs[0][0]  # æ‰€æœ‰ pair çš„ query ç›¸åŒ
        documents = [pair[1] for pair in pairs]

        try:
            response = TextReRank.call(
                model=self.model_name,
                query=query,
                documents=documents
            )

            if response.status_code == 200:
                # æå–åˆ†æ•°
                scores = [result['relevance_score'] for result in response.output.results]
                return scores
            else:
                print(f"âš ï¸ é˜¿é‡Œäº‘ Rerank è°ƒç”¨å¤±è´¥: {response.message}")
                return [0.5] * len(pairs)  # è¿”å›é»˜è®¤åˆ†æ•°

        except Exception as e:
            print(f"âš ï¸ é˜¿é‡Œäº‘ Rerank å¼‚å¸¸: {e}")
            return [0.5] * len(pairs)